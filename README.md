# math-Llama

In this project, I finetuend Llama-2 7B chat model on dataset containing 10k samples of problem-solution Paris

The finetuned model: https://huggingface.co/datafreak/math-Llama2


The raw dataset: [lighteval](https://huggingface.co/datasets/lighteval/MATH)

The formatted dataset: [formatted dataset](https://huggingface.co/datasets/datafreak/MATH-Llama2-10k)

To get a thorough understanding of my approach, here is the medium article accompanying the project: [Article](https://medium.com/@datafreakai/leveraging-language-models-for-advanced-mathematical-computation-and-problem-solving-cbd396e7a6e7)

